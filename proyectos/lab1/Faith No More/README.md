# Faith No More ‚Äì Data Cleaning & Preparation

Este repositorio contiene una **demostraci√≥n pr√°ctica** y un conjunto de **ejercicios guiados** sobre **limpieza y preparaci√≥n de datos** en Python, basados en el cap√≠tulo 7 *Data Cleaning and Preparation* del libro [*Python for Data Analysis* de Wes McKinney](https://wesmckinney.com/book/).

## Contenido

* üìì **`demo_faith_no_more.ipynb`**
  Notebook de **demostraci√≥n** en el que se aplican t√©cnicas comunes de limpieza de datos utilizando **Pandas y Numpy**.

  * Dataset utilizado: **Titanic**, cargado directamente desde la librer√≠a `seaborn`.

* üìì **`ejercicios_faith_no_more.ipynb`**
  Notebook con **7 ejercicios pr√°cticos** dise√±ados para aplicar los conceptos de limpieza y preparaci√≥n de datos.

  * Dataset utilizado: **Netflix Movies and TV Shows**, ubicado en:

    ```
    datasets/Alumnos/Equipo Faith No More/Netflix Movies and TV Shows/netflix_titles.csv
    ```
  * Ejercicios incluidos:

    1. **Relleno de valores faltantes** ‚Üí Imputar valores vac√≠os en la columna `director`.
    2. **Normalizaci√≥n de texto** ‚Üí Estandarizar nombres de pa√≠ses (`country`) en may√∫sculas.
    3. **Conversi√≥n de fechas** ‚Üí Transformar `date_added` a tipo `datetime` para an√°lisis temporal.
    4. **Creaci√≥n de variables derivadas** ‚Üí Identificar si un t√≠tulo es un documental.
    5. **Creaci√≥n de variables dummies** ‚Üí Convertir la columna `type` (Movie/TV Show) en variables binarias.
    6. **Categorizaci√≥n expl√≠cita** ‚Üí Definir `rating` como `Categorical` y explorar sus categor√≠as.
    7. **Correcci√≥n de ratings** ‚Üí Detectar y limpiar valores inv√°lidos en la columna `rating`.

* üìÑ **`requirements.txt`**
  Lista de dependencias necesarias para ejecutar los notebooks.

## Instalaci√≥n de dependencias

Para instalar las librer√≠as necesarias:

```bash
pip install -r requirements.txt
```

## Objetivo

El objetivo principal de este proyecto es **aprender y practicar t√©cnicas de limpieza y preparaci√≥n de datos** que resultan fundamentales antes de realizar an√°lisis exploratorio o aplicar modelos de machine learning.
